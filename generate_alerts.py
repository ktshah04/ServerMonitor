#!/usr/bin/env python3
"""Generate Grafana alert rules from alerts_config.json"""

import json
import yaml
import re

def parse_duration_to_seconds(duration_str):
    """Convert duration string like '10s', '5m', '1h' to seconds"""
    match = re.match(r'(\d+)([smhd])', duration_str)
    if not match:
        raise ValueError(f"Invalid duration format: {duration_str}")

    value, unit = int(match.group(1)), match.group(2)
    multipliers = {'s': 1, 'm': 60, 'h': 3600, 'd': 86400}
    return value * multipliers[unit]

# Load alerts configuration
with open('config/alerts_config.json', 'r') as f:
    alerts_config = json.load(f)

# Store alert rules
alert_rules = []

def create_alert(uid, title, expr, summary, description, for_duration, threshold, alert_type="system", evaluator_type="gt"):
    """Create a Grafana unified alert rule"""
    return {
        "uid": uid,
        "title": title,
        "condition": "C",
        "data": [
            {
                "refId": "A",
                "relativeTimeRange": {"from": 600, "to": 0},
                "datasourceUid": "prometheus",
                "model": {
                    "expr": expr,
                    "interval": "",
                    "refId": "A",
                    "datasource": {"type": "prometheus", "uid": "prometheus"}
                }
            },
            {
                "refId": "B",
                "relativeTimeRange": {"from": 0, "to": 0},
                "datasourceUid": "-100",
                "model": {
                    "datasource": {"type": "__expr__", "uid": "-100"},
                    "expression": "A",
                    "reducer": "last",
                    "refId": "B",
                    "type": "reduce"
                }
            },
            {
                "refId": "C",
                "relativeTimeRange": {"from": 0, "to": 0},
                "datasourceUid": "-100",
                "model": {
                    "datasource": {"type": "__expr__", "uid": "-100"},
                    "conditions": [{
                        "evaluator": {"params": [threshold], "type": evaluator_type},
                        "operator": {"type": "and"},
                        "query": {"params": ["B"]},
                        "type": "query"
                    }],
                    "expression": "B",
                    "refId": "C",
                    "type": "threshold"
                }
            }
        ],
        "noDataState": "NoData",
        "execErrState": "Alerting",
        "for": for_duration,
        "annotations": {"summary": summary, "description": description},
        "labels": {"alert_type": alert_type},
        "isPaused": False
    }

# CPU alert
if alerts_config.get("cpu_alerts", {}).get("enabled"):
    cfg = alerts_config["cpu_alerts"]
    alert_rules.append(create_alert(
        uid="cpu-usage-alert",
        title="CPU Usage Alert",
        expr='100 - (avg by(instance, hostname) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)',
        summary=f"CPU usage has been above {cfg['threshold_percent']}% for {cfg['sustained_duration']}",
        description=f"CPU usage has exceeded {cfg['threshold_percent']}% for {cfg['sustained_duration']}",
        for_duration=cfg["sustained_duration"],
        threshold=cfg["threshold_percent"]
    ))

# Memory alert
if alerts_config.get("memory_alerts", {}).get("enabled"):
    cfg = alerts_config["memory_alerts"]
    alert_rules.append(create_alert(
        uid="memory-usage-alert",
        title="Memory Usage Alert",
        expr='100 * (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes))',
        summary=f"Memory usage has been above {cfg['threshold_percent']}% for {cfg['sustained_duration']}",
        description=f"Memory usage has exceeded {cfg['threshold_percent']}% for {cfg['sustained_duration']}",
        for_duration=cfg["sustained_duration"],
        threshold=cfg["threshold_percent"]
    ))

# Storage alert - single dynamic alert for all physical drives
if alerts_config.get("storage_alerts", {}).get("enabled"):
    cfg = alerts_config["storage_alerts"]
    # Matches: /rootfs, /rootfs/home, /rootfs/mnt/data[0-9]+
    # Excludes: network mounts, tmpfs, other system paths
    storage_expr = '100 * (1 - (node_filesystem_avail_bytes{mountpoint=~"^/rootfs$|/rootfs/home$|/rootfs/mnt/data[0-9]+$",fstype!="tmpfs"} / node_filesystem_size_bytes{mountpoint=~"^/rootfs$|/rootfs/home$|/rootfs/mnt/data[0-9]+$",fstype!="tmpfs"}))'

    alert_rules.append(create_alert(
        uid="storage-alert-physical-drives",
        title="Storage Alert",
        expr=storage_expr,
        summary=f"Drive is more than {cfg['threshold_percent']}% full",
        description="",
        for_duration=cfg["sustained_duration"],
        threshold=cfg["threshold_percent"],
        alert_type="storage"
    ))

# Storage projection alert - warns when a drive is projected to fill within N days
if alerts_config.get("storage_projection_alerts", {}).get("enabled"):
    cfg = alerts_config["storage_projection_alerts"]
    days = cfg["days_until_full_threshold"]
    lookback = cfg["lookback_window"]
    seconds_ahead = 86400 * days

    projection_expr = (
        f'predict_linear(node_filesystem_avail_bytes{{mountpoint=~"^/rootfs$|/rootfs/home$|/rootfs/mnt/data[0-9]+$",'
        f'fstype!="tmpfs"}}[{lookback}], {seconds_ahead})'
    )

    alert_rules.append(create_alert(
        uid="storage-projection-alert",
        title="Storage Projection Alert",
        expr=projection_expr,
        summary=f"Drive projected to fill within {days} days",
        description=f"Based on {lookback} usage trend, drive is projected to run out of space within {days} days",
        for_duration=cfg["sustained_duration"],
        threshold=0,
        alert_type="storage_projection",
        evaluator_type="lt",
    ))

# Write alert rules with global check interval
with open('config/alert_rules.yml', 'w') as f:
    f.write("# AUTO-GENERATED FILE - DO NOT EDIT MANUALLY\n")
    f.write("# This file is generated by generate_alerts.py\n")
    f.write("# To make changes, edit config/alerts_config.json and run: python3 generate_alerts.py\n\n")
    yaml.dump({
        "apiVersion": 1,
        "groups": [{
            "orgId": 1,
            "name": "server_monitoring_alerts",
            "folder": "Server Monitoring",
            "interval": alerts_config["check_interval"],
            "rules": alert_rules
        }]
    }, f, default_flow_style=False, sort_keys=False)

def seconds_to_duration(seconds: int) -> str:
    if seconds >= 86400 and seconds % 86400 == 0:
        return f"{seconds // 86400}d"
    elif seconds >= 3600 and seconds % 3600 == 0:
        return f"{seconds // 3600}h"
    elif seconds >= 60 and seconds % 60 == 0:
        return f"{seconds // 60}m"
    else:
        return f"{seconds}s"

def repeat_interval_for(alert_cfg: dict) -> str:
    check_interval_seconds = parse_duration_to_seconds(alerts_config["check_interval"])
    notif_seconds = parse_duration_to_seconds(alert_cfg["notification_interval"])
    repeat_seconds = max(notif_seconds - check_interval_seconds, check_interval_seconds)
    return seconds_to_duration(repeat_seconds)

system_repeat = repeat_interval_for(alerts_config["cpu_alerts"])
storage_repeat = repeat_interval_for(alerts_config["storage_alerts"])
projection_repeat = repeat_interval_for(alerts_config["storage_projection_alerts"])

with open('config/notification_policies.yml', 'w') as f:
    f.write("# AUTO-GENERATED FILE - DO NOT EDIT MANUALLY\n")
    f.write("# This file is generated by generate_alerts.py\n")
    f.write("# To make changes, edit config/alerts_config.json and run: python3 generate_alerts.py\n\n")
    yaml.dump({
        "apiVersion": 1,
        "policies": [{
            "receiver": "slack-alerts-system",
            "group_by": ["alertname"],
            "group_wait": "0s",
            "group_interval": alerts_config["check_interval"],
            "repeat_interval": system_repeat,
            "routes": [
                {
                    "receiver": "slack-alerts-storage",
                    "matchers": ["alert_type=storage"],
                    "group_by": ["alertname"],
                    "group_wait": "0s",
                    "group_interval": alerts_config["check_interval"],
                    "repeat_interval": storage_repeat
                },
                {
                    "receiver": "slack-alerts-storage-projection",
                    "matchers": ["alert_type=storage_projection"],
                    "group_by": ["alertname"],
                    "group_wait": "0s",
                    "group_interval": alerts_config["check_interval"],
                    "repeat_interval": projection_repeat
                }
            ]
        }]
    }, f, default_flow_style=False, sort_keys=False)

print(f"Generated {len(alert_rules)} alert rules successfully!")
